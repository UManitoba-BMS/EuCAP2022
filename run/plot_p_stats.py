"""
Spencer Christie
University of Manitoba
July 26th, 2021
"""


import os

from pathlib import Path

from scipy import stats

import numpy as np

import matplotlib.pyplot as plt

from umbms.pathing import findpaths as fp
from umbms import processdata as procd

from umbms import get_proj_path, verify_path, get_script_logger

from umbms.loadsave import save_pickle


# TODO: Redo documentation

###############################################################################

all_sessions = os.listdir(os.path.join(get_proj_path(), 'data/'))

for session_str in all_sessions:


    __DATA_DIR = os.path.join(get_proj_path(), 'data/%s/' % session_str)

    __OUT_DIR = os.path.join(get_proj_path(), 'output/%s/' % session_str)
    verify_path(__OUT_DIR)

    ##############################################################
    # This is the control panel, with all the important variables that
    # determine how this script operates. These are the only variables
    # that should be changed.

    alpha = 0.05  # Confidence level for t-test chart. Change as you wish.
    save = True  # if true, saves figures, else shows them to you.
    # If compare_tri_1 is true, crops the data with respect to Triton 1
    # and 'compares' (does a t-test with the alternative hypothesis of
    # 'greater') the highest mean adipose response to Plastic Shell 1.
    # If False, crops by Triton 2 and compares to Plastic Shell 2.
    compare_tri_1 = True
    ##############################################################

    # Load the names and file paths of the scans, which is done via a
    # "key" which is  really just a plain text document in the data
    # directory that has the names of all the scans in an ordered list.
    scan_names = fp.load_session_md(session_dir=__DATA_DIR)
    scan_paths = fp.load_session_fd(n_expts=len(scan_names), session_dir=__DATA_DIR)

    # Delete the air scan because it is not needed here:
    for ii in range(len(scan_names)):

        if scan_names[ii].startswith("Air"):

            scan_names = np.delete(arr=scan_names, obj=ii)
            scan_paths = np.delete(arr=scan_paths, obj=ii)

    # initialize these early to avoid warnings:
    crop_name = None
    crop_scan = None
    comparison_scan = None

    # If we want to compare with Triton 1 as the crop scan, find its
    # info.
    if compare_tri_1:

        for ii in range(len(scan_names)):

            if scan_names[ii].startswith("Triton 1"):

                crop_scan = scan_paths[ii]
                crop_name = scan_names[ii]
                comparison_scan = "Plastic Shell 1"
                print("Cropping by %s, comparing highest adipose means"
                      " to %s." % (crop_name, comparison_scan))

    # If we don't want to compare with Triton 1 as the crop scan, compare
    # with Triton 2 instead.
    else:

        for ii in range(len(scan_names)):

            if scan_names[ii].startswith("Triton 2"):

                crop_scan = scan_paths[ii]
                crop_name = scan_names[ii]
                comparison_scan = "Plastic Shell 2"
                print("Cropping by %s, comparing to highest adipose means"
                      " to %s." % (crop_name, comparison_scan))

    if crop_name is None or comparison_scan is None or crop_scan is None:
        raise Exception("Some needed data files weren't found! Check data folder.")

    # This script graphs p-values over a range of crop values from 0 to 1
    cutoff_thresholds = np.linspace(0, 1, 100)

    # Named constants for the ICZT transform.
    INITIAL_TIME = 0.5e-9  # In seconds
    FINAL_TIME = 5.5e-9  # In seconds
    NMBR_OF_TIME_PNTS = 700
    INITIAL_FREQ = 1e9  # In hz
    FINAL_FREQ = 8e9  # In hz
    AXIS = 0

    # Any frequencies below this cutoff_freq are removed before we convert
    # to the time domain.
    cutoff_freq = 1.65e9  # In hz

    # Now that we have all the important variables defined...

    # Need to get the size and shape of the array generated by
    # the BIRRS software. So create a test data array:
    test_array, new_i_freq = procd.get_cut_td(data_path=scan_paths[0],
                                              c_data_path=scan_paths[1],
                                              i_time=INITIAL_TIME, f_time=FINAL_TIME,
                                              time_pnts=NMBR_OF_TIME_PNTS,
                                              i_freq=INITIAL_FREQ, f_freq=FINAL_FREQ,
                                              freq_cut=cutoff_freq, show_cut=True)
    row_amount, column_amount = test_array.shape
    print("Number of rows is %s and number of columns is %s"
          % (row_amount, column_amount))

    # For each scan...
    for ii in range(len(scan_names)):

        # The loop iterates over all scans, but we actually only want to
        # iterate over all reference (adipose) scans. So skip the loop
        # if it is not an adipose scan:
        if not scan_names[ii].startswith("Adipose"):
            continue

        # Get the reference scan:
        ref_scan_path = scan_paths[ii]
        ref_scan_name = scan_names[ii]
        print("%s is currently the reference." % scan_names[ii])

        # Make local numpy lists where the reference scan is deleted.
        # The reference is subtracted from all scans, so it itself cannot
        # be shown whilst being used as a reference.
        new_scan_names = np.delete(arr=scan_names, obj=ii)
        new_scan_paths = np.delete(arr=scan_paths, obj=ii)
        new_scan_data = np.zeros(shape=(len(new_scan_paths), row_amount,
                                        column_amount))

        crop_array = procd.get_cut_td(data_path=crop_scan,
                                      c_data_path=ref_scan_path,
                                      i_time=INITIAL_TIME, f_time=FINAL_TIME,
                                      time_pnts=NMBR_OF_TIME_PNTS,
                                      i_freq=INITIAL_FREQ, f_freq=FINAL_FREQ,
                                      freq_cut=cutoff_freq)

        # For each of the new_scan_paths (AKA all scans but the reference):
        for jj in range(len(new_scan_paths)):

            # Get the data for that scan:
            new_scan_data[jj] = procd.get_cut_td(data_path=new_scan_paths[jj],
                                                 c_data_path=ref_scan_path,
                                                 i_time=INITIAL_TIME,
                                                 f_time=FINAL_TIME,
                                                 time_pnts=NMBR_OF_TIME_PNTS,
                                                 i_freq=INITIAL_FREQ,
                                                 f_freq=FINAL_FREQ,
                                                 freq_cut=cutoff_freq)
            print("%s data was just obtained." % new_scan_names[jj])

        # Now that we have the data...

        # We need to initialize a few arrays to store the means/standard
        # deviations of each of the scans.
        data_means = np.zeros(shape=(len(new_scan_paths), len(cutoff_thresholds)))
        data_stds = np.zeros(shape=(len(new_scan_paths), len(cutoff_thresholds)))
        data_observe = np.zeros(shape=(len(cutoff_thresholds)))

        # For each of the new_scan_paths...
        for jj in range(len(new_scan_paths)):

            # For each of the cutoff_thresholds...
            for kk in range(len(cutoff_thresholds)):

                # Get the means and stds. roi_analysis also gives the
                # data set itself, which is used to find the number of
                # observations in each roi.
                data, data_means[jj, kk], data_stds[jj, kk] =\
                    procd.get_roi_1d_stats(array=new_scan_data[jj],
                                           cutoff=cutoff_thresholds[kk],
                                           roi_array=crop_array)
                data_observe[kk] = len(data)

        # We now have the data for the means and standard deviations for
        # every single scan over a range of threshold values. Now, what
        # we want to do is make an array that has only the highest
        # homogeneous means, and then compare those means to the those
        # in the plastic shell in a statistical t-test:

        # Initialize the arrays for storing the highest means/stds
        high_homo_means = np.zeros(shape=len(data_observe))
        high_homo_stds = np.zeros(shape=len(data_observe))

        # Initialize this now, can only find it later.
        comp_scan_index = None

        # For each of the scans...
        for jj in range(len(new_scan_names)):

            # For each threshold...
            for kk in range(len(cutoff_thresholds)):

                # If the scan is an adipose one...
                if new_scan_names[jj].startswith("Adipose"):

                    if high_homo_means[kk] < data_means[jj, kk]:

                        high_homo_means[kk] = data_means[jj, kk]
                        high_homo_stds[kk] = data_stds[jj, kk]

                # Else if we find the comparison_scan, save its index.
                elif new_scan_names[jj].startswith(comparison_scan):
                    comp_scan_index = jj

        if comp_scan_index is None:
            raise Exception("Comparison scan index not found. Maybe a misspell?")

        # Declare some variables before we do the t-tests:
        p_values = np.zeros(shape=len(cutoff_thresholds))
        df_check = False  # df for 'degrees of freedom'
        df_line = None

        for jj in range(len(p_values)):

            # Compare the comparison scan to the highest homogeneous means,
            # with the null hypothesis that they are equal, and the
            # specified alternative hypothesis that the comparison scan
            # is greater.
            t_stat, p_values[jj] = \
                stats.ttest_ind_from_stats(mean1=data_means[comp_scan_index, jj],
                                           std1=data_stds[comp_scan_index, jj],
                                           nobs1=data_observe[jj],
                                           mean2=high_homo_means[jj],
                                           std2=high_homo_stds[jj],
                                           nobs2=data_observe[jj],
                                           equal_var=False,
                                           alternative='greater')

            if data_observe[jj] < 40 and not df_check:
                df_line = cutoff_thresholds[jj]
                df_check = True

        # Now plotting the figures...
        plt.rc('font', family='Times New Roman')
        plt.rcParams['figure.figsize'] = (8, 6)
        plt.plot(cutoff_thresholds, p_values, 'k-')
        save_pickle((cutoff_thresholds, p_values),
                    os.path.join(__OUT_DIR + "\\" + "Ref_of_" + ref_scan_name \
                             + "_cropped_by_" + crop_name + "_" \
                             + str(NMBR_OF_TIME_PNTS) + "_time_points" + ".pickle"))
        plt.tick_params(labelsize=20)
        plt.xlabel("Threshold Value", fontsize=20)
        plt.ylabel("P Value", fontsize=20)
        plt.title("Comparing %s to highest Adipose \n"
                  " (%s is reference)" % (comparison_scan, ref_scan_name),
                  fontsize=20)
        # plt.axhline(y=alpha, xmin=0, xmax=1, color='black',
        #             linestyle='--', label="Alpha = %s" % alpha, linewidth=1.5)
        # plt.axvline(x=df_line, linestyle='-', ymin=-0.005, ymax=1.005,
        #             color='black', label="Number of observations < 40",
        #             linewidth=1.2)
        # plt.legend(loc='upper left', fontsize=18)
        plt.xlim(0, 1)
        # Make the y limits a little over/under 1/0 just so the p values
        # are visible if they happen to be 1/0.
        plt.ylim(-0.005, 1.005)

        if save:

            save_file_path = __OUT_DIR + "\\" + "Ref_of_" + ref_scan_name \
                             + "_cropped_by_" + crop_name + "_" \
                             + str(NMBR_OF_TIME_PNTS) + "_time_points" + ".png"
            plt.savefig(fname=save_file_path, dpi=300, transparent=False)
            plt.clf()

        else:
            plt.show()

        plt.close('all')